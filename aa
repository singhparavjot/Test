import requests
import csv
from datetime import datetime
from azure.identity import DefaultAzureCredential

# Set up authentication for Azure and Databricks
subscription_id = "your_subscription_id"
credential = DefaultAzureCredential()
access_token = credential.get_token("https://management.azure.com/.default").token

# Set up headers for Azure and Databricks APIs
azure_headers = {
    'Authorization': f'Bearer {access_token}',
    'Content-Type': 'application/json'
}

# Set up your Databricks PAT (Personal Access Token) 
databricks_token = "your_databricks_token"
databricks_headers = {
    'Authorization': f'Bearer {databricks_token}'
}

# Azure Cost Management API endpoint
cost_management_url = f"https://management.azure.com/subscriptions/{subscription_id}/providers/Microsoft.CostManagement/query?api-version=2021-10-01"

# Define the time range for September 2024
time_period = {
    "type": "Custom",
    "timeframe": "Custom",
    "timePeriod": {
        "from": "2024-09-01T00:00:00Z",
        "to": "2024-09-30T23:59:59Z"
    }
}

# Define the request body for cost data, filtering specifically for Databricks workspaces
request_body = {
    "type": "Usage",
    "dataSet": {
        "granularity": "Daily",
        "aggregation": {
            "totalCost": {
                "name": "PreTaxCost",
                "function": "Sum"
            }
        },
        "grouping": [
            {
                "type": "Dimension",
                "name": "ResourceId"
            }
        ],
        "filter": {
            "dimensions": {
                "name": "ResourceType",
                "operator": "In",
                "values": ["Microsoft.Databricks/workspaces"]
            }
        }
    },
    "timeframe": "Custom",
    "timePeriod": time_period
}

# Retrieve cost data for the specified period
response = requests.post(cost_management_url, headers=azure_headers, json=request_body)
cost_data = response.json()

# Prepare to store data for CSV
csv_data = [["ResourceId", "Workspace Name", "Node Type", "Date", "Cost"]]

# Loop through cost data and retrieve Databricks cluster information for node types
for item in cost_data['data']['rows']:
    resource_id = item[0]
    cost_date = item[1]
    total_cost = item[2]

    # Derive the workspace URL and call the Databricks API
    workspace_name = resource_id.split('/')[-1]
    host_name = f"{workspace_name}.azuredatabricks.net"

    # Retrieve cluster information for the workspace
    clusters_url = f"https://{host_name}/api/2.0/clusters/list"
    clusters_response = requests.get(clusters_url, headers=databricks_headers).json()

    # Process each cluster and extract node type
    for cluster in clusters_response.get('clusters', []):
        node_type = cluster.get('node_type_id', 'Unknown')

        # Append to CSV data
        csv_data.append([resource_id, workspace_name, node_type, cost_date, total_cost])

# Write data to CSV file
csv_file = "databricks_costs_september_2024.csv"
with open(csv_file, mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerows(csv_data)

print(f"Data written to {csv_file}")
