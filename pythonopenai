import os
from datetime import datetime, timedelta
from azure.identity import DefaultAzureCredential
from azure.mgmt.monitor import MonitorManagementClient

# Replace with your Azure details
subscription_id = 'your_subscription_id'
resource_group = 'your_resource_group'
openai_account_name = 'your_openai_account_name'
deployment_name = 'gpt-4o'  # Replace with your model deployment name

# Initialize Azure Monitor client
credential = DefaultAzureCredential()
monitor_client = MonitorManagementClient(credential, subscription_id)

# Construct the resource ID for Azure OpenAI
resource_id = f"/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{openai_account_name}"

# Define the timespan for usage data (e.g., last day)
timespan = f"{(datetime.utcnow() - timedelta(days=1)).isoformat()}/{datetime.utcnow().isoformat()}"

# Query Processed Inference Tokens with Sum aggregation
metrics_data = monitor_client.metrics.list(
    resource_id,
    timespan=timespan,
    interval=None,
    metricnames="ProcessedInferenceTokens",
    aggregation="Sum",
    filter=f"ModelDeploymentName eq '{deployment_name}'"
)

# Process and calculate the cost
total_tokens = sum(
    data.total for metric in metrics_data.value
    for timeseries in metric.timeseries
    for data in timeseries.data if data.total
)

# Define the cost per 1,000 tokens based on model type
cost_per_1000_tokens = 0.06  # Adjust based on Azure's pricing for GPT-4 or other models
cost = (total_tokens / 1000) * cost_per_1000_tokens

# Display the results
print(f"Deployment: {deployment_name}")
print(f"Total Processed Tokens: {total_tokens}")
print(f"Estimated Cost: ${cost:.4f}")
